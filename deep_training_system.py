#!/usr/bin/env python3
"""
ðŸ§  DEEP TRAINING SYSTEM - Training sÃ¢u vá»›i dá»¯ liá»‡u chuyÃªn sÃ¢u
Táº¡o vÃ  training vá»›i hÃ ng nghÃ¬n Q&A pairs chuyÃªn sÃ¢u vá» PC gaming
"""

import sqlite3
import json
import time
import random
from datetime import datetime
from typing import List, Dict, Tuple
import logging

import torch
import torch.nn.functional as F
from transformers import (
    AutoTokenizer, AutoModelForCausalLM, 
    TrainingArguments, Trainer, DataCollatorForLanguageModeling
)
from datasets import Dataset
import requests

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DeepTrainingDataGenerator:
    """Táº¡o dá»¯ liá»‡u training sÃ¢u cho PC gaming AI"""
    
    def __init__(self, db_path="conversations.db"):
        self.db_path = db_path
        
        # PC Gaming knowledge base - DEEP DATA
        self.deep_pc_knowledge = {
            "cpu_data": [
                {
                    "name": "Intel Core i7-13700F",
                    "specs": "16 cores (8P+8E), 24 threads, 3.4-5.2GHz",
                    "price": "9,500,000",
                    "gaming_performance": "Excellent cho gaming 1440p/4K",
                    "pros": ["Hiá»‡u nÄƒng cao", "Äa nhiá»‡m tá»‘t", "Tiáº¿t kiá»‡m Ä‘iá»‡n"],
                    "cons": ["GiÃ¡ cao", "Cáº§n táº£n nhiá»‡t tá»‘t"],
                    "use_cases": ["Gaming cao cáº¥p", "Streaming", "Content creation"]
                },
                {
                    "name": "AMD Ryzen 7 7700X",
                    "specs": "8 cores, 16 threads, 4.5-5.4GHz",
                    "price": "8,800,000",
                    "gaming_performance": "Tuyá»‡t vá»i cho gaming, hiá»‡u nÄƒng/giÃ¡ tá»‘t",
                    "pros": ["Hiá»‡u nÄƒng/giÃ¡ tá»‘t", "Tiáº¿t kiá»‡m Ä‘iá»‡n", "Overclock tá»‘t"],
                    "cons": ["Cáº§n RAM DDR5", "GiÃ¡ mainboard cao"],
                    "use_cases": ["Gaming", "Productivity", "Budget high-end"]
                },
                {
                    "name": "Intel Core i5-13400F",
                    "specs": "10 cores (6P+4E), 16 threads, 2.5-4.6GHz",
                    "price": "4,500,000",
                    "gaming_performance": "Ráº¥t tá»‘t cho gaming 1080p/1440p",
                    "pros": ["GiÃ¡ tá»‘t", "Hiá»‡u nÄƒng á»•n", "TÆ°Æ¡ng thÃ­ch rá»™ng"],
                    "cons": ["Ãt core hÆ¡n i7", "KhÃ´ng cÃ³ iGPU"],
                    "use_cases": ["Gaming mainstream", "Office", "Budget build"]
                }
            ],
            
            "gpu_data": [
                {
                    "name": "RTX 4070",
                    "specs": "12GB GDDR6X, 2610MHz boost",
                    "price": "14,500,000",
                    "gaming_performance": "1440p Ultra 60+ FPS, 4K Medium-High",
                    "ray_tracing": "Excellent vá»›i DLSS 3",
                    "vram": "12GB Ä‘á»§ cho gaming hiá»‡n táº¡i vÃ  tÆ°Æ¡ng lai",
                    "power": "200W TGP",
                    "pros": ["VRAM 12GB", "DLSS 3", "Hiá»‡u nÄƒng tá»‘t"],
                    "cons": ["GiÃ¡ cao", "Cáº§n PSU 650W+"],
                    "use_cases": ["Gaming 1440p", "Content creation", "Ray tracing"]
                },
                {
                    "name": "RTX 4060 Ti",
                    "specs": "16GB GDDR6, 2540MHz boost",
                    "price": "10,500,000",
                    "gaming_performance": "1440p High 60+ FPS, 1080p Ultra",
                    "ray_tracing": "Good vá»›i DLSS",
                    "vram": "16GB version tá»‘t cho tÆ°Æ¡ng lai",
                    "power": "165W TGP",
                    "pros": ["VRAM 16GB", "Tiáº¿t kiá»‡m Ä‘iá»‡n", "GiÃ¡ há»£p lÃ½"],
                    "cons": ["Bus 128-bit", "Hiá»‡u nÄƒng 1440p háº¡n cháº¿"],
                    "use_cases": ["Gaming 1080p/1440p", "Budget high-end"]
                },
                {
                    "name": "RTX 4060",
                    "specs": "8GB GDDR6, 2460MHz boost",
                    "price": "8,200,000",
                    "gaming_performance": "1080p Ultra 60+ FPS, 1440p Medium-High",
                    "ray_tracing": "Decent vá»›i DLSS",
                    "vram": "8GB Ä‘á»§ cho 1080p gaming",
                    "power": "115W TGP",
                    "pros": ["Tiáº¿t kiá»‡m Ä‘iá»‡n", "GiÃ¡ tá»‘t", "Compact"],
                    "cons": ["VRAM 8GB háº¡n cháº¿", "Hiá»‡u nÄƒng 1440p tháº¥p"],
                    "use_cases": ["Gaming 1080p", "Budget gaming", "SFF builds"]
                }
            ],
            
            "ram_data": [
                {
                    "type": "DDR4-3200 16GB",
                    "price": "1,200,000",
                    "performance": "Äá»§ cho gaming hiá»‡n táº¡i",
                    "compatibility": "TÆ°Æ¡ng thÃ­ch rá»™ng vá»›i Intel/AMD",
                    "pros": ["GiÃ¡ ráº»", "TÆ°Æ¡ng thÃ­ch tá»‘t", "á»”n Ä‘á»‹nh"],
                    "cons": ["Cháº­m hÆ¡n DDR5", "KhÃ´ng future-proof"],
                    "use_cases": ["Budget builds", "Upgrade cÅ©", "Gaming 1080p"]
                },
                {
                    "type": "DDR5-5600 32GB",
                    "price": "3,800,000",
                    "performance": "Excellent cho gaming vÃ  productivity",
                    "compatibility": "Intel 12th gen+, AMD Ryzen 7000+",
                    "pros": ["Tá»‘c Ä‘á»™ cao", "Future-proof", "Äa nhiá»‡m tá»‘t"],
                    "cons": ["GiÃ¡ cao", "TÆ°Æ¡ng thÃ­ch háº¡n cháº¿"],
                    "use_cases": ["High-end gaming", "Content creation", "Future builds"]
                }
            ],
            
            "storage_data": [
                {
                    "type": "SSD NVMe PCIe 4.0 1TB",
                    "price": "2,200,000",
                    "performance": "7000+ MB/s read, game load cá»±c nhanh",
                    "pros": ["Tá»‘c Ä‘á»™ cao", "Future-proof", "Game load nhanh"],
                    "cons": ["GiÃ¡ cao hÆ¡n PCIe 3.0", "Cáº§n mainboard há»— trá»£"],
                    "use_cases": ["Gaming", "OS drive", "High-end builds"]
                },
                {
                    "type": "SSD SATA 1TB",
                    "price": "1,500,000",
                    "performance": "550 MB/s, Ä‘á»§ cho gaming",
                    "pros": ["GiÃ¡ tá»‘t", "TÆ°Æ¡ng thÃ­ch rá»™ng", "ÄÃ¡ng tin cáº­y"],
                    "cons": ["Cháº­m hÆ¡n NVMe", "Cáº§n cÃ¡p SATA"],
                    "use_cases": ["Budget builds", "Secondary storage", "Upgrade cÅ©"]
                }
            ]
        }
        
        # Build configurations
        self.build_configs = {
            "budget_15m": {
                "cpu": "i5-13400F",
                "gpu": "RTX 4060",
                "ram": "DDR4-3200 16GB",
                "storage": "SSD SATA 500GB",
                "total": "15,000,000",
                "performance": "1080p Ultra gaming",
                "use_case": "Gaming entry-level"
            },
            "mid_range_25m": {
                "cpu": "i7-13700F",
                "gpu": "RTX 4060 Ti",
                "ram": "DDR4-3200 32GB",
                "storage": "SSD NVMe 1TB",
                "total": "25,000,000",
                "performance": "1440p High gaming",
                "use_case": "Gaming mainstream"
            },
            "high_end_35m": {
                "cpu": "i7-13700F",
                "gpu": "RTX 4070",
                "ram": "DDR5-5600 32GB",
                "storage": "SSD NVMe PCIe 4.0 1TB",
                "total": "35,000,000",
                "performance": "1440p Ultra, 4K Medium gaming",
                "use_case": "Gaming cao cáº¥p"
            }
        }
    
    def generate_deep_qa_pairs(self) -> List[Tuple[str, str]]:
        """Generate hÃ ng nghÃ¬n Q&A pairs chuyÃªn sÃ¢u"""
        qa_pairs = []
        
        # 1. CPU Q&A
        for cpu in self.deep_pc_knowledge["cpu_data"]:
            qa_pairs.extend([
                (f"CPU {cpu['name']} cÃ³ tá»‘t khÃ´ng?", 
                 f"{cpu['name']} {cpu['gaming_performance']}. Specs: {cpu['specs']}. GiÃ¡: {cpu['price']} VND. Æ¯u Ä‘iá»ƒm: {', '.join(cpu['pros'])}. PhÃ¹ há»£p cho: {', '.join(cpu['use_cases'])}."),
                
                (f"GiÃ¡ {cpu['name']} bao nhiÃªu?",
                 f"{cpu['name']} hiá»‡n táº¡i giÃ¡ khoáº£ng {cpu['price']} VND. {cpu['gaming_performance']}. ÄÃ¢y lÃ  lá»±a chá»n tá»‘t cho {', '.join(cpu['use_cases'])}."),
                
                (f"Specs {cpu['name']} nhÆ° tháº¿ nÃ o?",
                 f"{cpu['name']} cÃ³ {cpu['specs']}. {cpu['gaming_performance']}. Æ¯u Ä‘iá»ƒm: {', '.join(cpu['pros'])}. NhÆ°á»£c Ä‘iá»ƒm: {', '.join(cpu['cons'])}."),
                
                (f"{cpu['name']} gaming Ä‘Æ°á»£c khÃ´ng?",
                 f"CÃ³! {cpu['name']} {cpu['gaming_performance']}. Vá»›i {cpu['specs']}, CPU nÃ y phÃ¹ há»£p cho {', '.join(cpu['use_cases'])}. GiÃ¡ {cpu['price']} VND."),
                
                (f"NÃªn mua {cpu['name']} khÃ´ng?",
                 f"NÃªn! {cpu['name']} lÃ  lá»±a chá»n tá»‘t vá»›i {cpu['gaming_performance']}. Æ¯u Ä‘iá»ƒm: {', '.join(cpu['pros'])}. PhÃ¹ há»£p náº¿u báº¡n cáº§n {', '.join(cpu['use_cases'])}."),
            ])
        
        # 2. GPU Q&A
        for gpu in self.deep_pc_knowledge["gpu_data"]:
            qa_pairs.extend([
                (f"GPU {gpu['name']} cÃ³ tá»‘t khÃ´ng?",
                 f"{gpu['name']} ráº¥t tá»‘t! {gpu['gaming_performance']}. VRAM: {gpu['vram']}, TGP: {gpu['power']}. Ray tracing: {gpu['ray_tracing']}. GiÃ¡: {gpu['price']} VND."),
                
                (f"RTX {gpu['name'].split()[-1]} gaming Ä‘Æ°á»£c khÃ´ng?",
                 f"ÄÆ°á»£c! {gpu['name']} {gpu['gaming_performance']}. {gpu['ray_tracing']}. Æ¯u Ä‘iá»ƒm: {', '.join(gpu['pros'])}. PhÃ¹ há»£p cho: {', '.join(gpu['use_cases'])}."),
                
                (f"GiÃ¡ {gpu['name']} bao nhiÃªu?",
                 f"{gpu['name']} giÃ¡ khoáº£ng {gpu['price']} VND. Vá»›i hiá»‡u nÄƒng {gpu['gaming_performance']}, Ä‘Ã¢y lÃ  lá»±a chá»n tá»‘t cho {', '.join(gpu['use_cases'])}."),
                
                (f"{gpu['name']} chÆ¡i game 1440p Ä‘Æ°á»£c khÃ´ng?",
                 f"ÄÆ°á»£c! {gpu['name']} {gpu['gaming_performance']}. VRAM {gpu['vram']} Ä‘á»§ cho gaming 1440p. {gpu['ray_tracing']}."),
                
                (f"So sÃ¡nh {gpu['name']} vá»›i card khÃ¡c?",
                 f"{gpu['name']}: {gpu['gaming_performance']}. Æ¯u Ä‘iá»ƒm: {', '.join(gpu['pros'])}. NhÆ°á»£c Ä‘iá»ƒm: {', '.join(gpu['cons'])}. TGP: {gpu['power']}."),
            ])
        
        # 3. Build Q&A
        for build_name, config in self.build_configs.items():
            budget = config['total']
            qa_pairs.extend([
                (f"Build PC {budget} Ä‘Æ°á»£c gÃ¬?",
                 f"PC {budget}: CPU {config['cpu']}, GPU {config['gpu']}, RAM {config['ram']}, SSD {config['storage']}. Hiá»‡u nÄƒng: {config['performance']}. PhÃ¹ há»£p cho: {config['use_case']}."),
                
                (f"Cáº¥u hÃ¬nh PC gaming {budget}?",
                 f"Gá»£i Ã½ PC {budget}: {config['cpu']} + {config['gpu']} + {config['ram']} + {config['storage']}. ChÆ¡i game {config['performance']}. Tá»•ng: {config['total']} VND."),
                
                (f"PC {budget} chÆ¡i game Ä‘Æ°á»£c khÃ´ng?",
                 f"ÄÆ°á»£c! PC {budget} vá»›i {config['cpu']} + {config['gpu']} cÃ³ thá»ƒ {config['performance']}. Cáº¥u hÃ¬nh nÃ y phÃ¹ há»£p cho {config['use_case']}."),
            ])
        
        # 4. Comparison Q&A
        qa_pairs.extend([
            ("Intel vs AMD CPU nÃ o tá»‘t hÆ¡n?",
             "Intel: Hiá»‡u nÄƒng gaming cao, tÆ°Æ¡ng thÃ­ch tá»‘t. AMD: GiÃ¡/hiá»‡u nÄƒng tá»‘t, tiáº¿t kiá»‡m Ä‘iá»‡n. Intel tá»‘t cho gaming thuáº§n, AMD tá»‘t cho Ä‘a nhiá»‡m."),
            
            ("RTX vs GTX khÃ¡c nhau gÃ¬?",
             "RTX cÃ³ Ray Tracing vÃ  DLSS, hiá»‡u nÄƒng cao hÆ¡n. GTX giÃ¡ ráº» hÆ¡n nhÆ°ng khÃ´ng cÃ³ RT/DLSS. RTX phÃ¹ há»£p gaming cao cáº¥p, GTX cho budget."),
            
            ("DDR4 vs DDR5 nÃªn chá»n gÃ¬?",
             "DDR5: Nhanh hÆ¡n, future-proof nhÆ°ng Ä‘áº¯t. DDR4: Ráº», tÆ°Æ¡ng thÃ­ch rá»™ng. Chá»n DDR5 cho build má»›i cao cáº¥p, DDR4 cho budget/upgrade."),
            
            ("SSD vs HDD nÃªn dÃ¹ng gÃ¬?",
             "SSD: Nhanh, game load nhanh, bá»n. HDD: Ráº», dung lÆ°á»£ng lá»›n. DÃ¹ng SSD cho OS/game, HDD cho lÆ°u trá»¯."),
        ])
        
        # 5. Troubleshooting Q&A
        qa_pairs.extend([
            ("PC khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c?",
             "Kiá»ƒm tra: 1) Nguá»“n Ä‘iá»‡n, 2) RAM láº¯p cháº·t, 3) CÃ¡p 24pin + 8pin CPU, 4) GPU láº¯p cháº·t, 5) Monitor cáº¯m Ä‘Ãºng cá»•ng GPU."),
            
            ("Game bá»‹ lag, giáº­t?",
             "NguyÃªn nhÃ¢n: 1) GPU yáº¿u, 2) RAM khÃ´ng Ä‘á»§, 3) CPU bottleneck, 4) Nhiá»‡t Ä‘á»™ cao, 5) Driver cÅ©. Kiá»ƒm tra tá»«ng cÃ¡i."),
            
            ("PC nÃ³ng quÃ¡?",
             "Giáº£i phÃ¡p: 1) Vá»‡ sinh quáº¡t, 2) Thay keo táº£n nhiá»‡t, 3) ThÃªm quáº¡t case, 4) Kiá»ƒm tra airflow, 5) Undervolt CPU/GPU."),
            
            ("MÃ n hÃ¬nh khÃ´ng cÃ³ tÃ­n hiá»‡u?",
             "Kiá»ƒm tra: 1) CÃ¡p monitor, 2) Cáº¯m vÃ o GPU khÃ´ng pháº£i mainboard, 3) RAM láº¯p cháº·t, 4) GPU cÃ³ nguá»“n, 5) Monitor báº­t Ä‘Ãºng input."),
        ])
        
        logger.info(f"Generated {len(qa_pairs)} deep Q&A pairs")
        return qa_pairs
    
    def save_deep_training_data(self, qa_pairs: List[Tuple[str, str]]):
        """Save deep training data to database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        for question, answer in qa_pairs:
            try:
                cursor.execute('''
                    INSERT INTO conversations (user_id, message, response, confidence, source)
                    VALUES (?, ?, ?, ?, ?)
                ''', ('deep_training', question, answer, 0.95, 'deep_generated'))
                saved_count += 1
            except Exception as e:
                logger.error(f"Error saving Q&A: {e}")
        
        conn.commit()
        conn.close()
        
        logger.info(f"ðŸ’¾ Saved {saved_count} deep training pairs to database")
        return saved_count
    
    def generate_and_save_deep_data(self):
        """Generate vÃ  save táº¥t cáº£ deep training data"""
        logger.info("ðŸ§  Generating deep training data...")
        
        # Generate Q&A pairs
        qa_pairs = self.generate_deep_qa_pairs()
        
        # Save to database
        saved_count = self.save_deep_training_data(qa_pairs)
        
        logger.info(f"âœ… Deep training data generation complete: {saved_count} pairs")
        return saved_count

class DeepTrainingSystem:
    """Deep training system vá»›i enhanced model"""
    
    def __init__(self, model_name="microsoft/DialoGPT-medium"):
        self.model_name = model_name
        self.db_path = "conversations.db"
        self.model_save_path = "./deep_trained_model"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        logger.info(f"Using device: {self.device}")
        if torch.cuda.is_available():
            logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
    
    def load_model(self):
        """Load model for deep training"""
        logger.info(f"Loading {self.model_name} for deep training...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        self.model = AutoModelForCausalLM.from_pretrained(self.model_name)
        self.model.to(self.device)
        
        logger.info("âœ… Model loaded successfully")
    
    def get_deep_training_data(self) -> List[Tuple[str, str]]:
        """Get all training data for deep training"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get all conversations including deep generated ones
        cursor.execute('''
            SELECT message, response FROM conversations 
            WHERE confidence > 0.7
            ORDER BY timestamp DESC
        ''')
        
        training_data = cursor.fetchall()
        conn.close()
        
        logger.info(f"ðŸ“Š Retrieved {len(training_data)} training samples")
        return training_data
    
    def deep_train_model(self):
        """Perform deep training"""
        logger.info("ðŸ§  Starting DEEP TRAINING...")
        
        # Get training data
        training_data = self.get_deep_training_data()
        
        if len(training_data) < 10:
            logger.error("Not enough training data for deep training")
            return False
        
        # Prepare training texts
        texts = []
        for question, answer in training_data:
            text = f"{question}{self.tokenizer.eos_token}{answer}{self.tokenizer.eos_token}"
            texts.append(text)
        
        # Tokenize
        logger.info("ðŸ”¤ Tokenizing training data...")
        encodings = self.tokenizer(
            texts,
            truncation=True,
            padding=True,
            max_length=512,
            return_tensors="pt"
        )
        
        dataset = Dataset.from_dict({
            "input_ids": encodings["input_ids"],
            "attention_mask": encodings["attention_mask"]
        })
        
        # Training arguments for deep training
        training_args = TrainingArguments(
            output_dir=self.model_save_path,
            overwrite_output_dir=True,
            num_train_epochs=3,  # More epochs for deep training
            per_device_train_batch_size=2,  # Smaller batch for deeper training
            gradient_accumulation_steps=4,  # Accumulate gradients
            save_steps=50,
            save_total_limit=3,
            prediction_loss_only=True,
            learning_rate=3e-5,  # Lower learning rate for stability
            warmup_steps=100,
            logging_steps=10,
            fp16=torch.cuda.is_available(),
            dataloader_drop_last=True,
        )
        
        # Data collator
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False,
        )
        
        # Trainer
        trainer = Trainer(
            model=self.model,
            args=training_args,
            data_collator=data_collator,
            train_dataset=dataset,
        )
        
        # Deep training
        logger.info(f"ðŸš€ Deep training with {len(training_data)} samples...")
        trainer.train()
        
        # Save deep trained model
        trainer.save_model()
        self.tokenizer.save_pretrained(self.model_save_path)
        
        logger.info("âœ… DEEP TRAINING COMPLETED!")
        return True

def main():
    """Main function for deep training"""
    logger.info("ðŸ§  STARTING DEEP TRAINING SYSTEM...")
    
    # 1. Generate deep training data
    data_generator = DeepTrainingDataGenerator()
    data_generator.generate_and_save_deep_data()
    
    # 2. Perform deep training
    training_system = DeepTrainingSystem()
    training_system.load_model()
    training_system.deep_train_model()
    
    logger.info("ðŸŽ‰ DEEP TRAINING SYSTEM COMPLETE!")

if __name__ == "__main__":
    main()
